{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 노선 없는 ",
   "id": "ee36bcca773442a6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-10T05:16:42.591758Z",
     "start_time": "2024-09-10T05:16:40.678545Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dtype_spec = {\n",
    "    'DAY_TYPE': 'int8',\n",
    "    'BUSINFOUNIT_ID': 'str',\n",
    "    'LEN': 'int32',\n",
    "    'DEP_TIME': 'str',\n",
    "    'TIME_GAP': 'float32',\n",
    "    'SPEED': 'float32'\n",
    "}\n",
    "\n",
    "# CSV 파일들이 있는 폴더 경로 (예시로 'dataset_0904' 폴더라고 가정)\n",
    "folder_path = r'C:\\Users\\seung\\SynologyDrive\\Projects\\딥러닝\\dataset_0909\\infounit_ALL_SCHEDULE'\n",
    "\n",
    "# CSV 파일들을 하나의 DataFrame으로 합침\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 순차적으로 읽어서 합침\n",
    "for file_name in sorted(os.listdir(folder_path)):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path, dtype=dtype_spec)\n",
    "        all_data = (pd.concat([all_data, df], ignore_index=True)\n",
    "                    # .sort_values(['BUSUNITINFO_ID', 'DEP_TIME'], ascending=[True, True])\n",
    "                    .drop_duplicates())\n",
    "        \n",
    "all_data.sort_values(by=['BUSINFOUNIT_ID', 'DEP_TIME'], inplace=True)\n",
    "\n",
    "# 빈 줄이 생기지 않도록 처리하고 하나의 파일로 저장\n",
    "output_file = r'C:\\Users\\seung\\SynologyDrive\\Projects\\딥러닝\\dataset_0909\\infounit_ALL_SCHEDULE\\combined_infounit_ALL_SCHEDULE.csv'\n",
    "all_data.to_csv(output_file, index=False, lineterminator='\\n')\n",
    "\n",
    "print(\"CSV 파일 병합 완료!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 병합 완료!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 노선 있는 ",
   "id": "709c33abf5781f14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T01:42:28.104634Z",
     "start_time": "2024-09-27T01:42:27.789908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dtype_spec = {\n",
    "    'DAY_TYPE': 'int8',\n",
    "    'BUSROUTE_ID': 'str',\n",
    "    'BUSINFOUNIT_ID': 'str',\n",
    "    'LEN': 'int32',\n",
    "    'DEP_TIME': 'str',\n",
    "    'TIME_GAP': 'float32',\n",
    "    'SPEED': 'float32',\n",
    "}\n",
    "usecols = ['DAY_TYPE', 'BUSROUTE_ID', 'BUSINFOUNIT_ID', 'LEN', 'DEP_TIME', 'TIME_GAP', 'SPEED']\n",
    "\n",
    "# CSV 파일들이 있는 폴더 경로\n",
    "# folder_path = '../../dataset/inference/travel/240920'\n",
    "folder_path = r'D:\\WorkSpaces\\pyCharm_workspace\\busArrivalPred\\dataset\\inference\\travel\\240927_7,8공휴일'\n",
    "\n",
    "# CSV 파일들을 하나의 DataFrame으로 합침\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 순차적으로 읽어서 합침\n",
    "for file_name in sorted(os.listdir(folder_path)):\n",
    "    if file_name.lower().endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path, usecols=usecols, dtype=dtype_spec)\n",
    "        \n",
    "        # 전체 행 개수 기록\n",
    "        initial_rows = len(df)\n",
    "        \n",
    "        # SPEED 컬럼의 NaN 또는 빈 값 제거\n",
    "        before_speed_drop = len(df)\n",
    "        df = df.dropna(subset=['SPEED'])\n",
    "        df = df[df['SPEED'] != '']\n",
    "        after_speed_drop = len(df)\n",
    "        print(f\"{file_name}: SPEED 제거된 행의 수: {before_speed_drop - after_speed_drop}\")\n",
    "\n",
    "        # TIME_GAP 컬럼의 NaN 또는 빈 값 제거\n",
    "        before_time_gap_drop = len(df)\n",
    "        df = df.dropna(subset=['TIME_GAP'])\n",
    "        df = df[df['TIME_GAP'] != '']\n",
    "        after_time_gap_drop = len(df)\n",
    "        print(f\"{file_name}: TIME_GAP 제거된 행의 수: {before_time_gap_drop - after_time_gap_drop}\")\n",
    "\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # TIME_GAP 컬럼 정수로 변환\n",
    "        df['TIME_GAP'] = df['TIME_GAP'].astype('int32')\n",
    "        # SPEED 컬럼 정수로 반올림\n",
    "        df['SPEED'] = df['SPEED'].round().astype('int32')\n",
    "        \n",
    "        all_data = (pd.concat([all_data, df], ignore_index=True)\n",
    "                    # .sort_values(['BUSROUTE_ID', 'BUSINFOUNIT_ID', 'DEP_TIME'], ascending=[True, True, True])\n",
    "                    # .drop_duplicates()\n",
    "                    )\n",
    "        \n",
    "        final_rows = len(df)\n",
    "        print(f\"{file_name}: 초기 행의 수: {initial_rows}, 최종 남은 행의 수: {final_rows}\")\n",
    "\n",
    "before_dedup = len(all_data)\n",
    "all_data = all_data.drop_duplicates()\n",
    "after_dedup = len(all_data)\n",
    "print(f\"\\n중복 제거 행의 수: {before_dedup - after_dedup}\")\n",
    "\n",
    "all_data.sort_values(by=['BUSROUTE_ID', 'BUSINFOUNIT_ID', 'DEP_TIME'], inplace=True)\n",
    "\n",
    "# 빈 줄이 생기지 않도록 처리하고 하나의 파일로 저장\n",
    "output_file = folder_path + '/combined.csv'\n",
    "# output_file = r'C:\\Users\\seung\\SynologyDrive\\Projects\\딥러닝\\DATASET_0911\\raw\\inference\\inf_combined.csv'\n",
    "all_data.to_csv(output_file, index=False, lineterminator='\\n')\n",
    "\n",
    "print(\"\\nCSV 파일 병합 완료!\")\n",
    "print(f\"병합된 전체 행 수: {len(all_data)}\")\n"
   ],
   "id": "21cb5dd0cf1037c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.7소통_0709.csv: SPEED 제거된 행의 수: 56391\n",
      "9.7소통_0709.csv: TIME_GAP 제거된 행의 수: 0\n",
      "9.7소통_0709.csv: 초기 행의 수: 95348, 최종 남은 행의 수: 38957\n",
      "9.7소통_1315.csv: SPEED 제거된 행의 수: 58732\n",
      "9.7소통_1315.csv: TIME_GAP 제거된 행의 수: 0\n",
      "9.7소통_1315.csv: 초기 행의 수: 95348, 최종 남은 행의 수: 36616\n",
      "9.7소통_1820.csv: SPEED 제거된 행의 수: 58319\n",
      "9.7소통_1820.csv: TIME_GAP 제거된 행의 수: 0\n",
      "9.7소통_1820.csv: 초기 행의 수: 95348, 최종 남은 행의 수: 37029\n",
      "\n",
      "중복 제거 행의 수: 0\n",
      "\n",
      "CSV 파일 병합 완료!\n",
      "병합된 전체 행 수: 112602\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 정차시간",
   "id": "fece821f74cda016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T06:05:47.111660Z",
     "start_time": "2024-09-26T06:05:44.637122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dtype_spec = {\n",
    "    'DAY_TYPE': 'int8',\n",
    "    'BUSROUTE_ID': 'str',\n",
    "    'BUSSTOP_ID': 'str',\n",
    "    'DEP_TIME': 'str',\n",
    "    'TIME_GAP': 'float32',\n",
    "}\n",
    "usecols = ['DAY_TYPE', 'BUSROUTE_ID', 'BUSSTOP_ID', 'DEP_TIME', 'TIME_GAP']\n",
    "\n",
    "# CSV 파일들이 있는 폴더 경로\n",
    "folder_path = r'D:\\WorkSpaces\\pyCharm_workspace\\busArrivalPred\\dataset\\train\\holding\\240927_7,8공휴일\\aa'\n",
    "\n",
    "# CSV 파일들을 하나의 DataFrame으로 합침\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 순차적으로 읽어서 합침\n",
    "for file_name in sorted(os.listdir(folder_path)):\n",
    "    if file_name.lower().endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path, usecols=usecols, dtype=dtype_spec)\n",
    "        \n",
    "        # 전체 행 개수 기록\n",
    "        initial_rows = len(df)\n",
    "\n",
    "        # TIME_GAP 컬럼의 NaN 또는 빈 값 제거\n",
    "        before_time_gap_drop = len(df)\n",
    "        df = df.dropna(subset=['TIME_GAP'])\n",
    "        df = df[df['TIME_GAP'] != '']\n",
    "        after_time_gap_drop = len(df)\n",
    "        print(f\"{file_name}: TIME_GAP 제거된 행의 수: {before_time_gap_drop - after_time_gap_drop}\")\n",
    "\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # TIME_GAP 컬럼 정수로 변환\n",
    "        df['TIME_GAP'] = df['TIME_GAP'].astype('int32')\n",
    "        \n",
    "        all_data = (pd.concat([all_data, df], ignore_index=True)\n",
    "                    # .sort_values(['BUSROUTE_ID', 'BUSINFOUNIT_ID', 'DEP_TIME'], ascending=[True, True, True])\n",
    "                    # .drop_duplicates()\n",
    "                    )\n",
    "        \n",
    "        final_rows = len(df)\n",
    "        print(f\"{file_name}: 초기 행의 수: {initial_rows}, 최종 남은 행의 수: {final_rows}\")\n",
    "\n",
    "before_dedup = len(all_data)\n",
    "all_data = all_data.drop_duplicates()\n",
    "after_dedup = len(all_data)\n",
    "print(f\"\\n중복 제거 행의 수: {before_dedup - after_dedup}\")\n",
    "\n",
    "all_data.sort_values(by=['BUSROUTE_ID', 'BUSSTOP_ID', 'DEP_TIME'], inplace=True)\n",
    "\n",
    "\n",
    "# 빈 줄이 생기지 않도록 처리하고 하나의 파일로 저장\n",
    "output_file = folder_path + '/combined.csv'\n",
    "# output_file = r'C:\\Users\\seung\\SynologyDrive\\Projects\\딥러닝\\DATASET_0911\\raw\\inference\\inf_combined.csv'\n",
    "all_data.to_csv(output_file, index=False, lineterminator='\\n')\n",
    "\n",
    "print(\"\\nCSV 파일 병합 완료!\")\n",
    "print(f\"병합된 전체 행 수: {len(all_data)}\")\n"
   ],
   "id": "13ab6fd53ce77f3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정차_3월~7월_1~2분.csv: TIME_GAP 제거된 행의 수: 0\n",
      "정차_3월~7월_1~2분.csv: 초기 행의 수: 472647, 최종 남은 행의 수: 472647\n",
      "정차_7,8월평일_긴거추가.csv: TIME_GAP 제거된 행의 수: 0\n",
      "정차_7,8월평일_긴거추가.csv: 초기 행의 수: 1225330, 최종 남은 행의 수: 1225330\n",
      "\n",
      "중복 제거 행의 수: 26874\n",
      "\n",
      "CSV 파일 병합 완료!\n",
      "병합된 전체 행 수: 1671103\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc1f49f9106c2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
